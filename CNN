import tensorflow as tf
import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score,explained_variance_score
import math
from keras.models import Sequential
from keras.layers import Dense,Dropout,Flatten,Conv1D,MaxPooling1D
SL = pd.read_csv(r"\Spyder\MyPython\mytest\SData.csv")
training_set = SL.iloc[0:9849- 980, 0:7].values
test_set = SL.iloc[9849- 980:9849, 0:7].values
Power = SL.iloc[0:9849 - 980, 6:7].values

sc = MinMaxScaler(feature_range=(0, 1)) 
training_set_scaled = sc.fit_transform(training_set)  
test_set = sc.transform(test_set) 
ss = MinMaxScaler(feature_range=(0, 1))
Power_set = ss.fit_transform(Power)

x_train = []
y_train = []

x_test = []
y_test = []

for i in range(49, len(training_set_scaled)):
    x_train.append(training_set_scaled[i - 49:i, 0:7])
    y_train.append(training_set_scaled[i, 6])

print(x_train)
np.random.seed(6)
np.random.shuffle(x_train)
np.random.seed(6)
np.random.shuffle(y_train)
tf.random.set_seed(6)

x_train, y_train = np.array(x_train), np.array(y_train)
x_train = np.reshape(x_train, (x_train.shape[0], 49, 7))
for i in range(49, len(test_set)):
    x_test.append(test_set[i - 49:i, 0:7])
    y_test.append(test_set[i, 6])
x_test, y_test = np.array(x_test), np.array(y_test)
x_test = np.reshape(x_test, (x_test.shape[0], 49, 7))

def build_model(input):
    model = Sequential()
    model.add(Dense(32,input_shape=(input[0],input[1])))
    model.add(Conv1D(filters=128,kernel_size=2,padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling1D(pool_size=2,padding='same'))
    model.add(Conv1D(filters=64,kernel_size=2,padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling1D(pool_size=2,padding='same'))
    model.add(Dropout(0.2))
    model.add(Flatten())
    model.add(Dense(64,activation='relu',kernel_initializer='uniform'))
    model.add(Dense(1,activation='relu',kernel_initializer='uniform'))
    model.compile(loss='mse',optimizer='adam',metrics=['mae'])
    return model 

model = build_model([49,7,1])

# Summary of the Model
print(model.summary())    



history = model.fit(x_train,
                    y_train,
                    batch_size=32,
                    epochs=50,
                    verbose=2)

# history
history_dict = history.history
history_dict.keys()

################## predict ######################

predicted_power = model.predict(x_test)
predicted_power = ss.inverse_transform(predicted_power)
predicted_power[predicted_power<0] = 0
predicted_power = predicted_power[:,0:1]
real_power = SL.iloc[9849-931:9849, 6:7].values

# plt.plot(real_power, color='red', label='power')
# plt.plot(predicted_power, color='blue', label='Predicted power')
# plt.title('power prediction')
# plt.xlabel('Time')
# plt.ylabel('power')
# plt.legend()
# plt.show()

##########evaluate##############
# mse = mean_squared_error(predicted_power, real_power)
rmse = math.sqrt(mean_squared_error(predicted_power, real_power))
mae = mean_absolute_error(predicted_power, real_power)
R2 = r2_score(predicted_power, real_power)
# evs = explained_variance_score(predicted_power, real_power)
def mape(predicted_power, real_power):
    mask=real_power!=0
    return np.mean(np.abs((predicted_power[mask] - real_power[mask]) / real_power[mask]))*100

# print('MSE: %.6f' % mse)
print('RMSE: %.6f' % rmse)
print('MAE: %.6f' % mae)
print('R2: %.6f' % R2)
# print(': %.6f' % evs)
print('MAPE:',mape(predicted_power, real_power))

